# src/rl_optimizer/utils/training_metrics_callback.py

import time
import numpy as np
from typing import Dict, Any, List, Optional
from collections import deque
from pathlib import Path

from stable_baselines3.common.callbacks import BaseCallback
from stable_baselines3.common.logger import Logger

from src.rl_optimizer.utils.setup import setup_logger

logger = setup_logger(__name__)


class TrainingMetricsCallback(BaseCallback):
    """
    è®­ç»ƒæŒ‡æ ‡å›è°ƒç±»ï¼Œç”¨äºè·Ÿè¸ªå’Œè®°å½•PPOè®­ç»ƒè¿‡ç¨‹ä¸­çš„å…³é”®æŒ‡æ ‡ã€‚
    
    ä¸»è¦åŠŸèƒ½ï¼š
    - è®°å½•æ¯ä¸ªepisodeçš„å®é™…åŠ æƒæ—¶é—´
    - è·Ÿè¸ªæœ€ä½³å¸ƒå±€å’Œæœ€ä½æ—¶é—´æˆæœ¬
    - æä¾›è®­ç»ƒè¿›åº¦çš„å®æ—¶åé¦ˆ
    - é›†æˆåˆ°TensorBoardè¿›è¡Œå¯è§†åŒ–
    """
    
    def __init__(
        self,
        log_freq: int = 100,
        save_freq: int = 1000,
        save_path: Optional[str] = None,
        window_size: int = 100,
        verbose: int = 1,
        total_episodes_target: Optional[int] = None
    ):
        """
        åˆå§‹åŒ–è®­ç»ƒæŒ‡æ ‡å›è°ƒã€‚
        
        Args:
            log_freq (int): æ¯å¤šå°‘ä¸ªepisodeè®°å½•ä¸€æ¬¡æ—¥å¿—
            save_freq (int): æ¯å¤šå°‘ä¸ªepisodeä¿å­˜ä¸€æ¬¡æŒ‡æ ‡å†å²
            save_path (Optional[str]): æŒ‡æ ‡ä¿å­˜è·¯å¾„
            window_size (int): æ»‘åŠ¨çª—å£å¤§å°ï¼Œç”¨äºè®¡ç®—å¹³å‡å€¼
            verbose (int): æ—¥å¿—è¯¦ç»†çº§åˆ«
            total_episodes_target (Optional[int]): æ€»çš„ç›®æ ‡episodesæ•°é‡ï¼Œç”¨äºæ˜¾ç¤ºè¿›åº¦æ¡
        """
        super().__init__(verbose)
        self.log_freq = log_freq
        self.save_freq = save_freq
        self.save_path = Path(save_path) if save_path else None
        self.window_size = window_size
        self.total_episodes_target = total_episodes_target
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºä¸»è¿›ç¨‹
        import multiprocessing
        try:
            self.is_main_process = multiprocessing.current_process().name == 'MainProcess'
        except:
            self.is_main_process = True
        
        # å¦‚æœä¸æ˜¯ä¸»è¿›ç¨‹ï¼Œé™ä½æ—¥å¿—è¯¦ç»†ç¨‹åº¦
        if not self.is_main_process:
            self.verbose = 0
        
        # æŒ‡æ ‡è·Ÿè¸ª
        self.episode_count = 0
        self.time_costs = deque(maxlen=window_size)
        self.rewards = deque(maxlen=window_size)
        self.episode_lengths = deque(maxlen=window_size)
        
        # æœ€ä½³ç»“æœè·Ÿè¸ª
        self.best_time_cost = float('inf')
        self.best_layout = None
        self.best_episode = 0
        
        # å†å²è®°å½•
        self.history = {
            'episodes': [],
            'time_costs': [],
            'rewards': [],
            'episode_lengths': [],
            'best_time_costs': [],
            'timestamps': []
        }
        
        # æ—¶é—´è·Ÿè¸ª
        self.start_time = time.time()
        self.last_log_time = time.time()
        
        if self.save_path:
            self.save_path.mkdir(parents=True, exist_ok=True)
            
    def _init_callback(self) -> None:
        """åˆå§‹åŒ–å›è°ƒæ—¶çš„æ“ä½œã€‚"""
        if self.verbose >= 1 and self.is_main_process:
            logger.info("è®­ç»ƒæŒ‡æ ‡å›è°ƒå·²åˆå§‹åŒ–")
            logger.info(f"æ—¥å¿—é¢‘ç‡: {self.log_freq} episodes")
            logger.info(f"ä¿å­˜é¢‘ç‡: {self.save_freq} episodes")
            if self.save_path:
                logger.info(f"æŒ‡æ ‡ä¿å­˜è·¯å¾„: {self.save_path}")
                
    def _on_step(self) -> bool:
        """æ¯ä¸ªè®­ç»ƒæ­¥åçš„å›è°ƒã€‚"""
        # åœ¨SB3çš„VecEnvä¸­ï¼Œepisodeä¿¡æ¯é€šè¿‡ä¸åŒæ–¹å¼ä¼ é€’
        # æ£€æŸ¥self.localsä¸­çš„infos
        infos = self.locals.get('infos', [])
        
        if self.verbose >= 2 and self.is_main_process:
            logger.debug(f"å›è°ƒæ¥æ”¶åˆ° {len(infos)} ä¸ªinfoï¼Œå†…å®¹: {infos}")
        
        if len(infos) > 0:
            for i, info in enumerate(infos):
                # æ£€æŸ¥æ˜¯å¦æœ‰episodeç»“æŸä¿¡æ¯
                if 'episode' in info:
                    if self.verbose >= 2 and self.is_main_process:
                        logger.debug(f"å‘ç°episodeç»“æŸä¿¡æ¯: {info['episode']}")
                    self._process_episode_end(info['episode'])
                
                # æ£€æŸ¥SB3æ ‡å‡†çš„episodeä¿¡æ¯æ ¼å¼
                elif '_episode' in info:
                    episode_data = info['_episode']
                    if self.verbose >= 2 and self.is_main_process:
                        logger.debug(f"å‘ç°SB3æ ¼å¼episodeä¿¡æ¯: {episode_data}")
                    self._process_episode_end(episode_data)
                
                # æ£€æŸ¥å…¶ä»–å¯èƒ½çš„episodeä¿¡æ¯å­—æ®µ
                elif any(key in info for key in ['terminal_observation', 'episode_info']):
                    if self.verbose >= 2 and self.is_main_process:
                        logger.debug(f"å‘ç°å…¶ä»–æ ¼å¼episodeä¿¡æ¯: {info}")
                    # å°è¯•æ„é€ episodeæ•°æ®
                    episode_data = {}
                    if 'episode_info' in info:
                        episode_data = info['episode_info']
                    self._process_episode_end(episode_data)
        
        return True
        
    def _process_episode_end(self, episode_info: Dict[str, Any]) -> None:
        """å¤„ç†episodeç»“æŸæ—¶çš„æŒ‡æ ‡ã€‚"""
        self.episode_count += 1
        
        # æå–episodeä¿¡æ¯
        episode_reward = episode_info.get('r', 0.0)
        episode_length = episode_info.get('l', 0)
        
        # æå–æ—¶é—´æˆæœ¬ï¼ˆå¦‚æœç¯å¢ƒæä¾›äº†çš„è¯ï¼‰
        time_cost = episode_info.get('time_cost', None)
        layout = episode_info.get('layout', None)
        
        # è®°å½•åˆ°æ»‘åŠ¨çª—å£
        self.rewards.append(episode_reward)
        self.episode_lengths.append(episode_length)
        
        if time_cost is not None:
            self.time_costs.append(time_cost)
            
            # æ›´æ–°æœ€ä½³ç»“æœ
            if time_cost < self.best_time_cost:
                self.best_time_cost = time_cost
                self.best_layout = layout
                self.best_episode = self.episode_count
                
                # åªæœ‰ä¸»è¿›ç¨‹è®°å½•æœ€ä½³ç»“æœå‘ç°æ—¥å¿—
                if self.verbose >= 1 and self.is_main_process:
                    scaled_reward = -time_cost / 1e4
                    logger.info(f"ğŸ‰ å‘ç°æ–°çš„æœ€ä½³å¸ƒå±€ï¼Episode {self.episode_count}: "
                              f"ã€åŸå§‹ã€‘æ—¶é—´æˆæœ¬ = {time_cost:.2f} ç§’ "
                              f"(å¯¹åº”ç¼©æ”¾reward: {scaled_reward:.6f})")
        
        # è®°å½•åˆ°å†å²ï¼ˆæ‰€æœ‰è¿›ç¨‹éƒ½è®°å½•ï¼Œä½†åªæœ‰ä¸»è¿›ç¨‹ä¿å­˜æ–‡ä»¶ï¼‰
        current_time = time.time()
        self.history['episodes'].append(self.episode_count)
        self.history['time_costs'].append(time_cost if time_cost is not None else float('nan'))
        self.history['rewards'].append(episode_reward)
        self.history['episode_lengths'].append(episode_length)
        self.history['best_time_costs'].append(self.best_time_cost)
        self.history['timestamps'].append(current_time)
        
        # å®šæœŸæ—¥å¿—è¾“å‡ºï¼ˆåªæœ‰ä¸»è¿›ç¨‹ï¼‰
        if self.episode_count % self.log_freq == 0 and self.is_main_process:
            self._log_metrics()
            
        # å®šæœŸä¿å­˜æŒ‡æ ‡ï¼ˆåªæœ‰ä¸»è¿›ç¨‹ï¼‰
        if (self.save_freq > 0 and self.episode_count % self.save_freq == 0 and 
            self.is_main_process):
            self._save_metrics()
            
        # TensorBoardæ—¥å¿—
        self._log_to_tensorboard(time_cost, episode_reward, episode_length)
        
    def _log_metrics(self) -> None:
        """è¾“å‡ºè®­ç»ƒæŒ‡æ ‡æ—¥å¿—ã€‚"""
        current_time = time.time()
        elapsed_time = current_time - self.start_time
        time_since_last_log = current_time - self.last_log_time
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        if self.time_costs:
            avg_time_cost = np.mean(self.time_costs)
            std_time_cost = np.std(self.time_costs)
            min_time_cost = np.min(self.time_costs)
            max_time_cost = np.max(self.time_costs)
        else:
            avg_time_cost = std_time_cost = min_time_cost = max_time_cost = float('nan')
            
        avg_reward = np.mean(self.rewards) if self.rewards else float('nan')
        avg_length = np.mean(self.episode_lengths) if self.episode_lengths else float('nan')
        
        # è®¡ç®—è®­ç»ƒé€Ÿåº¦
        episodes_per_second = self.log_freq / time_since_last_log if time_since_last_log > 0 else 0
        
        logger.info("=" * 80)
        logger.info(f"ğŸ“Š è®­ç»ƒæŒ‡æ ‡æŠ¥å‘Š - Episode {self.episode_count}")
        logger.info("-" * 80)
        logger.info(f"â±ï¸  è®­ç»ƒæ—¶é—´: {elapsed_time/3600:.2f} å°æ—¶")
        logger.info(f"ğŸš€ è®­ç»ƒé€Ÿåº¦: {episodes_per_second:.2f} episodes/ç§’")
        logger.info("")
        
        if not np.isnan(avg_time_cost):
            logger.info(f"ğŸ¯ ã€åŸå§‹ã€‘åŠ æƒæ—¶é—´æˆæœ¬ (æœ€è¿‘{len(self.time_costs)}ä¸ªepisodes):")
            logger.info(f"   å¹³å‡å€¼: {avg_time_cost:.2f} ç§’ Â± {std_time_cost:.2f}")
            logger.info(f"   èŒƒå›´: [{min_time_cost:.2f}, {max_time_cost:.2f}] ç§’")
            logger.info(f"   æœ€ä½³å€¼: {self.best_time_cost:.2f} ç§’ (Episode {self.best_episode})")
            
            # æ˜¾ç¤ºå¯¹åº”çš„ç¼©æ”¾å€¼ç”¨äºå¯¹æ¯”
            avg_scaled = -avg_time_cost / 1e4
            best_scaled = -self.best_time_cost / 1e4
            logger.info(f"   å¯¹æ¯”ï¼šå¹³å‡ç¼©æ”¾reward: {avg_scaled:.6f}, æœ€ä½³ç¼©æ”¾reward: {best_scaled:.6f}")
            logger.info("")
            
        logger.info(f"ğŸ† å¥–åŠ±ç»Ÿè®¡ (æœ€è¿‘{len(self.rewards)}ä¸ªepisodes):")
        logger.info(f"   å¹³å‡å¥–åŠ±: {avg_reward:.4f}")
        logger.info(f"   å¹³å‡é•¿åº¦: {avg_length:.1f} æ­¥")
        
        # æ·»åŠ è¿›åº¦æ¡æ˜¾ç¤ºï¼ˆå¦‚æœæœ‰æ€»ç›®æ ‡çš„è¯ï¼‰
        if hasattr(self, 'total_episodes_target') and self.total_episodes_target > 0:
            progress_percent = (self.episode_count / self.total_episodes_target) * 100
            progress_bar_length = 40
            filled_length = int(progress_bar_length * self.episode_count // self.total_episodes_target)
            bar = 'â–ˆ' * filled_length + 'â–‘' * (progress_bar_length - filled_length)
            logger.info(f"ğŸ“ˆ è®­ç»ƒè¿›åº¦: [{bar}] {progress_percent:.1f}% ({self.episode_count}/{self.total_episodes_target})")
        
        logger.info("=" * 80)
        
        self.last_log_time = current_time
        
    def _log_to_tensorboard(self, time_cost: Optional[float], reward: float, length: int) -> None:
        """è®°å½•æŒ‡æ ‡åˆ°TensorBoardã€‚"""
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„loggerï¼ˆåœ¨å›è°ƒæ­£å¼ä½¿ç”¨æ—¶æ‰æœ‰ï¼‰
        try:
            if hasattr(self, 'logger') and self.logger is not None:
                # åŸºæœ¬æŒ‡æ ‡
                self.logger.record("episode/reward", reward)
                self.logger.record("episode/length", length)
                self.logger.record("episode/count", self.episode_count)
                
                # æ—¶é—´æˆæœ¬æŒ‡æ ‡
                if time_cost is not None:
                    self.logger.record("episode/time_cost", time_cost)
                    self.logger.record("episode/best_time_cost", self.best_time_cost)
                    
                    # ç›¸å¯¹æ”¹è¿›
                    if self.best_time_cost > 0:
                        improvement = (time_cost - self.best_time_cost) / self.best_time_cost * 100
                        self.logger.record("episode/time_cost_vs_best_percent", improvement)
                
                # æ»‘åŠ¨å¹³å‡
                if len(self.time_costs) > 0:
                    self.logger.record("episode/avg_time_cost", np.mean(self.time_costs))
                if len(self.rewards) > 0:
                    self.logger.record("episode/avg_reward", np.mean(self.rewards))
                if len(self.episode_lengths) > 0:
                    self.logger.record("episode/avg_length", np.mean(self.episode_lengths))
        except Exception as e:
            # åœ¨æµ‹è¯•æˆ–å…¶ä»–ç‰¹æ®Šæƒ…å†µä¸‹ï¼Œloggerå¯èƒ½ä¸å¯ç”¨ï¼Œè¿™æ˜¯æ­£å¸¸çš„
            if self.verbose >= 2:
                logger.warning(f"TensorBoardæ—¥å¿—è®°å½•å¤±è´¥: {e}")
            
    def _save_metrics(self) -> None:
        """ä¿å­˜æŒ‡æ ‡å†å²åˆ°æ–‡ä»¶ã€‚"""
        if not self.save_path or not self.is_main_process:
            return
            
        try:
            import json
            
            # ä¿å­˜å®Œæ•´å†å²
            history_file = self.save_path / f"training_metrics_ep{self.episode_count}.json"
            with open(history_file, 'w', encoding='utf-8') as f:
                # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
                history_to_save = {}
                for key, values in self.history.items():
                    history_to_save[key] = [
                        float(v) if isinstance(v, (np.integer, np.floating)) else v 
                        for v in values
                    ]
                json.dump(history_to_save, f, ensure_ascii=False, indent=2)
                
            # ä¿å­˜æœ€ä½³ç»“æœ
            if self.best_layout is not None:
                best_file = self.save_path / f"best_layout_ep{self.episode_count}.json"
                best_info = {
                    "episode": self.best_episode,
                    "time_cost": float(self.best_time_cost),
                    "layout": self.best_layout,
                    "timestamp": time.time()
                }
                with open(best_file, 'w', encoding='utf-8') as f:
                    json.dump(best_info, f, ensure_ascii=False, indent=2)
                    
            if self.verbose >= 2:
                logger.info(f"è®­ç»ƒæŒ‡æ ‡å·²ä¿å­˜åˆ°: {self.save_path}")
                
        except Exception as e:
            logger.error(f"ä¿å­˜è®­ç»ƒæŒ‡æ ‡æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
            
    def get_best_result(self) -> Dict[str, Any]:
        """è·å–å½“å‰æœ€ä½³ç»“æœã€‚"""
        return {
            "episode": self.best_episode,
            "time_cost": self.best_time_cost,
            "layout": self.best_layout,
            "total_episodes": self.episode_count
        }
        
    def get_current_stats(self) -> Dict[str, Any]:
        """è·å–å½“å‰ç»Ÿè®¡ä¿¡æ¯ã€‚"""
        stats = {
            "episode_count": self.episode_count,
            "best_time_cost": self.best_time_cost,
            "best_episode": self.best_episode
        }
        
        if self.time_costs:
            stats.update({
                "avg_time_cost": float(np.mean(self.time_costs)),
                "std_time_cost": float(np.std(self.time_costs)),
                "min_time_cost": float(np.min(self.time_costs)),
                "max_time_cost": float(np.max(self.time_costs))
            })
            
        if self.rewards:
            stats.update({
                "avg_reward": float(np.mean(self.rewards)),
                "std_reward": float(np.std(self.rewards))
            })
            
        return stats